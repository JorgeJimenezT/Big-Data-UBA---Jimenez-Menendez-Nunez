{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1.Exploren el diseño de registro de la base de hogar: a priori, ¿qué variables creen pueden ser predictivas de la desocupación y seria útil incluir para perfeccionar el ejercicio del TP3? Mencionen estas variables y justifiquen su elección.\n",
        "\n"
      ],
      "metadata": {
        "id": "nio437QKyHRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGION (Región geográfica del hogar): Captura diferencias geográficas significativas en tasas de desempleo, relacionadas con el desarrollo económico local y acceso a oportunidades laborales.\n",
        "\n",
        "II7 (Tenencia de la vivienda): Refleja estabilidad económica del hogar. Hogares que alquilan pueden estar más presionados económicamente, mientras que aquellos que son propietarios pueden tener más estabilidad.\n",
        "\n",
        "CH03 (Relación de parentesco con el jefe de hogar): La relación con el jefe de hogar puede influir en la probabilidad de empleo o desempleo, ya que ciertos roles en la familia (como jefe o cónyuge) podrían tener mayores prioridades o responsabilidades económicas.\n",
        "\n",
        "IV12_3 (Ubicación en villa de emergencia): Refleja una condición de vulnerabilidad socioeconómica que puede limitar el acceso a oportunidades laborales y recursos.\n",
        "\n",
        "IV6 (Acceso al agua): El acceso al agua (por cañería, fuera del terreno, etc.) indica diferencias en las condiciones materiales del hogar, que podrían correlacionarse con el nivel de ingresos y empleo.\n",
        "\n",
        "IV11 (Desagüe del baño): El tipo de desagüe refleja el nivel de infraestructura y calidad de vida del hogar, indicadores que pueden influir en la estabilidad laboral.\n",
        "\n",
        "II8 (Tipo de combustible utilizado para cocinar): Hogares que utilizan gas de red tienen mejor infraestructura en comparación con aquellos que dependen de kerosene, leña o carbón, lo que puede relacionarse con el ingreso y empleo.\n",
        "\n",
        "CH12 (Nivel educativo más alto alcanzado): La educación es un factor determinante en el acceso al empleo. Los niveles educativos más altos (universitario o posgrado) están directamente relacionados con mejores oportunidades laborales y menores tasas de desempleo.\n",
        "\n",
        "ITF (Ingreso total familiar): Proporciona una medida global del ingreso familiar, relevante para evaluar la situación económica general del hogar y su relación con el empleo.\n",
        "\n",
        "IPCF (Ingreso per cápita familiar): Permite evaluar la disponibilidad de recursos económicos por persona en el hogar, siendo un indicador clave de bienestar económico y estabilidad."
      ],
      "metadata": {
        "id": "lGIaUbS63g3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Descarguen la base de microdatos de la EPH correspondiente al primer trimestre de 2004 y 2024 en formato .dta y .xls, respectivamente. La base de hogares se llama Hogar_t104.dta y usu_hogar_T124.xls, respectivamente. Eliminen todas las observaciones que no corresponden a los aglomerados de Ciuidad Autónoma de Buenos Aires o Gran Buenos Aires y unan ambos trimestres en una sola base. Esto es, a la base de la encuesta individual de cada año (que usaron en el TP3) unan la base de la encuesta de hogar. Asegúrese de estar usando las variables CODUSU y NRO_Hogar para el merge.\n"
      ],
      "metadata": {
        "id": "8on2SJKY5RVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadstat\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# URLs de los archivos\n",
        "url_2004 = \"https://github.com/JorgeJimenezT/Big-Data-UBA---Jimenez-Menendez-Nunez/raw/main/TP4/Hogar_t104.dta\"\n",
        "url_2024 = \"https://github.com/JorgeJimenezT/Big-Data-UBA---Jimenez-Menendez-Nunez/raw/main/TP4/usu_hogar_T124.xlsx\"\n",
        "\n",
        "# Descargar y guardar los archivos localmente\n",
        "file_2004 = \"Hogar_t104.dta\"\n",
        "file_2024 = \"usu_hogar_T124.xlsx\"\n",
        "\n",
        "# Descargar archivo 2004\n",
        "response_2004 = requests.get(url_2004)\n",
        "with open(file_2004, \"wb\") as f:\n",
        "    f.write(response_2004.content)\n",
        "\n",
        "# Descargar archivo 2024\n",
        "response_2024 = requests.get(url_2024)\n",
        "with open(file_2024, \"wb\") as f:\n",
        "    f.write(response_2024.content)\n",
        "\n",
        "# Cargar las bases de hogares para 2004 y 2024 usando pyreadstat y pandas\n",
        "hogar_2004, meta_2004 = pyreadstat.read_dta(file_2004)\n",
        "hogar_2024 = pd.read_excel(file_2024)\n",
        "\n",
        "# Estandarizar los nombres de las columnas\n",
        "hogar_2004.columns = [col.upper() for col in hogar_2004.columns]\n",
        "hogar_2024.columns = [col.upper() for col in hogar_2024.columns]\n",
        "\n",
        "# URLs directas de los archivos en GitHub\n",
        "url_i_2004 = \"https://github.com/JorgeJimenezT/Big-Data-UBA---Jimenez-Menendez-Nunez/raw/refs/heads/main/TP3/Individual_t104.dta\"\n",
        "url_i_2024 = \"https://github.com/JorgeJimenezT/Big-Data-UBA---Jimenez-Menendez-Nunez/raw/refs/heads/main/TP3/usu_individual_T124.xlsx\"\n",
        "\n",
        "# Leer los archivos directamente desde GitHub\n",
        "individual_2004 = pd.read_stata(url_i_2004)\n",
        "individual_2024 = pd.read_excel(url_i_2024)\n",
        "\n",
        "# Estandarizar los nombres de las columnas en los DataFrames individuales\n",
        "individual_2004.columns = [col.upper() for col in individual_2004.columns]\n",
        "individual_2024.columns = [col.upper() for col in individual_2024.columns]\n",
        "\n",
        "individual_2004['YEAR'] = 2004\n",
        "individual_2024['YEAR'] = 2024\n",
        "\n",
        "hogar_2004['YEAR'] = 2004\n",
        "hogar_2024['YEAR'] = 2024\n",
        "\n"
      ],
      "metadata": {
        "id": "RLZNOe6OBK66"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadstat\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "# Diccionario de mapeo: nombres a códigos\n",
        "aglomerado_mapping = {\n",
        "    \"Gran La Plata\": 2,\n",
        "    \"Bahía Blanca - Cerri\": 3,\n",
        "    \"Gran Rosario\": 4,\n",
        "    \"Gran Santa Fe\": 5,\n",
        "    \"Gran Paraná\": 6,\n",
        "    \"Posadas\": 7,\n",
        "    \"Gran Resistencia\": 8,\n",
        "    \"Cdro. Rivadavia – Rada Tilly\": 9,\n",
        "    \"Gran Mendoza\": 10,\n",
        "    \"Corrientes\": 12,\n",
        "    \"Gran Córdoba\": 13,\n",
        "    \"Concordia\": 14,\n",
        "    \"Formosa\": 15,\n",
        "    \"Neuquén – Plottier\": 17,\n",
        "    \"S.del Estero - La Banda\": 18,\n",
        "    \"Jujuy - Palpalá\": 19,\n",
        "    \"Río Gallegos\": 20,\n",
        "    \"Gran Catamarca\": 22,\n",
        "    \"Salta\": 23,\n",
        "    \"La Rioja\": 25,\n",
        "    \"San Luis - El Chorrillo\": 26,\n",
        "    \"Gran San Juan\": 27,\n",
        "    \"Gran Tucumán - T. Viejo\": 29,\n",
        "    \"Santa Rosa - Toay\": 30,\n",
        "    \"Ushuaia - Río Grande\": 31,\n",
        "    \"Ciudad de Buenos Aires\": 32,\n",
        "    \"Partidos del GBA\": 33,\n",
        "    \"Mar del Plata - Batán\": 34,\n",
        "    \"Río Cuarto\": 36\n",
        "}\n",
        "\n",
        "# Reemplazar nombres por códigos en la columna 'AGLOMERADO'\n",
        "hogar_2004['AGLOMERADO'] = hogar_2004['AGLOMERADO'].replace(aglomerado_mapping)\n",
        "hogar_2024['AGLOMERADO'] = hogar_2024['AGLOMERADO'].replace(aglomerado_mapping)\n",
        "\n",
        "estado_mapping = {\n",
        "    0: \"Entrevista no realizada\",\n",
        "    1: \"Ocupado\",\n",
        "    2: \"Desocupado\",\n",
        "    3: \"Inactivo\",\n",
        "    4: \"Menor de 10 años\"\n",
        "}\n",
        "\n",
        "# Reemplazar códigos numéricos por sus etiquetas correspondientes en la columna 'ESTADO'\n",
        "individual_2024['ESTADO'] = individual_2024['ESTADO'].replace(estado_mapping)\n",
        "\n",
        "# Diccionario de mapeo: códigos de NIVEL_ED a sus etiquetas\n",
        "nivel_ed_mapping_inverso = {\n",
        "    \"Primaria Incompleta\": 1,\n",
        "    \"Primaria Incompleta (incluye educación especial)\": 1,\n",
        "    \"Primaria Completa\": 2,\n",
        "    \"Secundaria Incompleta\": 3,\n",
        "    \"Secundaria Completa\": 4,\n",
        "    \"Superior Universitaria Incompleta\": 5,\n",
        "    \"Superior Universitaria Completa\": 6,\n",
        "    \"Sin instrucción\": 7,\n",
        "    \"Ns./Nr.\": 9\n",
        "}\n",
        "\n",
        "# Reemplazar valores en la columna 'NIVEL_ED' con sus códigos numéricos\n",
        "individual_2004['NIVEL_ED'] = individual_2004['NIVEL_ED'].replace(nivel_ed_mapping_inverso)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Filtrar aglomerados correspondientes a Ciudad Autónoma de Buenos Aires o Gran Buenos Aires\n",
        "ciudad_aglomerados = [32, 33]\n",
        "\n",
        "hogar_2004_filtered = hogar_2004[hogar_2004[\"AGLOMERADO\"].isin(ciudad_aglomerados)]\n",
        "hogar_2024_filtered = hogar_2024[hogar_2024[\"AGLOMERADO\"].isin(ciudad_aglomerados)]\n",
        "\n",
        "individual_2004_filtered = individual_2004[individual_2004[\"AGLOMERADO\"].isin(ciudad_aglomerados)]\n",
        "individual_2024_filtered = individual_2024[individual_2024[\"AGLOMERADO\"].isin(ciudad_aglomerados)]\n",
        "\n",
        "\n",
        "# Diagnóstico de las claves antes del merge\n",
        "print(\"Diagnóstico antes del merge:\")\n",
        "print(\"Valores únicos en 'CODUSU' y 'NRO_HOGAR' en hogar_2004:\", hogar_2004_filtered[[\"CODUSU\", \"NRO_HOGAR\"]].nunique())\n",
        "print(\"Valores únicos en 'CODUSU' y 'NRO_HOGAR' en individual_2004:\", individual_2004[[\"CODUSU\", \"NRO_HOGAR\"]].nunique())\n",
        "\n",
        "print(\"Valores únicos en 'CODUSU' y 'NRO_HOGAR' en hogar_2024:\", hogar_2024_filtered[[\"CODUSU\", \"NRO_HOGAR\"]].nunique())\n",
        "print(\"Valores únicos en 'CODUSU' y 'NRO_HOGAR' en individual_2024:\", individual_2024[[\"CODUSU\", \"NRO_HOGAR\"]].nunique())\n",
        "\n"
      ],
      "metadata": {
        "id": "kij4KN1-BLYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e978e82-7773-4575-ecb4-e654af222205"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnóstico antes del merge:\n",
            "Valores únicos en 'CODUSU' y 'NRO_HOGAR' en hogar_2004: CODUSU       2329\n",
            "NRO_HOGAR       3\n",
            "dtype: int64\n",
            "Valores únicos en 'CODUSU' y 'NRO_HOGAR' en individual_2004: CODUSU       12597\n",
            "NRO_HOGAR        6\n",
            "dtype: int64\n",
            "Valores únicos en 'CODUSU' y 'NRO_HOGAR' en hogar_2024: CODUSU       2540\n",
            "NRO_HOGAR       4\n",
            "dtype: int64\n",
            "Valores únicos en 'CODUSU' y 'NRO_HOGAR' en individual_2024: CODUSU       16005\n",
            "NRO_HOGAR        5\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-6cf7b1c3b31d>:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  individual_2004['NIVEL_ED'] = individual_2004['NIVEL_ED'].replace(nivel_ed_mapping_inverso)\n",
            "<ipython-input-20-6cf7b1c3b31d>:69: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
            "  individual_2004['NIVEL_ED'] = individual_2004['NIVEL_ED'].replace(nivel_ed_mapping_inverso)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir las columnas relevantes para hogares e individuales\n",
        "columnas_hogar = [\"CODUSU\", \"NRO_HOGAR\", \"REGION\", \"II7\", \"IV12_3\", \"IV6\", \"IV11\", \"II8\", \"ITF\", \"IPCF\",\"II1\",\"IX_TOT\"]\n",
        "columnas_individual = [\"CODUSU\", \"NRO_HOGAR\", \"CH03\", \"CH12\", \"CH06\",\"CH04\",\"NIVEL_ED\", \"ESTADO\"]\n",
        "\n",
        "# Asegurarse de crear copias explícitas\n",
        "hogar_2004_filtered = hogar_2004[columnas_hogar].copy()\n",
        "individual_2004_filtered = individual_2004[columnas_individual].copy()\n",
        "\n",
        "# Convertir NRO_HOGAR a tipo entero antes de transformarlo a cadena\n",
        "hogar_2004_filtered[\"NRO_HOGAR\"] = hogar_2004_filtered[\"NRO_HOGAR\"].fillna(0).astype(int).astype(str).str.strip()\n",
        "individual_2004_filtered[\"NRO_HOGAR\"] = individual_2004_filtered[\"NRO_HOGAR\"].fillna(0).astype(int).astype(str).str.strip()\n",
        "\n",
        "# Eliminar espacios adicionales en CODUSU\n",
        "hogar_2004_filtered[\"CODUSU\"] = hogar_2004_filtered[\"CODUSU\"].str.strip()\n",
        "individual_2004_filtered[\"CODUSU\"] = individual_2004_filtered[\"CODUSU\"].str.strip()\n",
        "\n",
        "#Colocar 0 en \"Menos de Un año\"\n",
        "individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"Menos de 1 año\", 0)\n",
        "individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"Menos de 1 año\", 0)\n",
        "individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"Menos de 1 aÃ±o\", 0)\n",
        "individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"Menos de 1 aÃ±o\", 0)\n",
        "\n",
        "individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"98 y más años\", 98)\n",
        "individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"98 y más años\", 98)\n",
        "individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"98 y mÃ¡s aÃ±os\", 98)\n",
        "individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"98 y mÃ¡s aÃ±os\", 98)\n",
        "\n",
        "\n",
        "# Filtrar las columnas en las bases de hogares\n",
        "hogar_2024_filtered = hogar_2024[columnas_hogar]\n",
        "\n",
        "# Filtrar las columnas en las bases individuales\n",
        "individual_2024_filtered = individual_2024[columnas_individual]\n",
        "\n",
        "# Realizar el merge entre las bases individuales y de hogares\n",
        "base_2004_i = pd.merge(individual_2004_filtered, hogar_2004_filtered, on=[\"CODUSU\", \"NRO_HOGAR\"], how=\"inner\")\n",
        "base_2024_i = pd.merge(individual_2024_filtered, hogar_2024_filtered, on=[\"CODUSU\", \"NRO_HOGAR\"], how=\"inner\")\n",
        "\n",
        "# Unir ambas bases en una sola y agregar el año\n",
        "base_2004_i[\"YEAR\"] = 2004\n",
        "base_2024_i[\"YEAR\"] = 2024\n",
        "\n"
      ],
      "metadata": {
        "id": "Bf19GloyZ2FS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e6d129-741e-4b6b-ea2e-864aeae38ede"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-121967ae814b>:20: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
            "  individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"Menos de 1 año\", 0)\n",
            "<ipython-input-21-121967ae814b>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"Menos de 1 año\", 0)\n",
            "<ipython-input-21-121967ae814b>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"Menos de 1 aÃ±o\", 0)\n",
            "<ipython-input-21-121967ae814b>:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"98 y más años\", 98)\n",
            "<ipython-input-21-121967ae814b>:25: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
            "  individual_2004_filtered['CH06'] = individual_2004_filtered['CH06'].replace(\"98 y más años\", 98)\n",
            "<ipython-input-21-121967ae814b>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"98 y más años\", 98)\n",
            "<ipython-input-21-121967ae814b>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  individual_2024_filtered['CH06'] = individual_2024_filtered['CH06'].replace(\"98 y mÃ¡s aÃ±os\", 98)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##3.Limpien la base de datos tomando criterios que hagan sentido. Explicar cualquier decisión como el tratamiento de valores faltantes (missing values), extremos (outliers), o variables categóricas. Justifique sus decisiones.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6gwkPWMj1H1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valores faltantes: Las filas con valores nulos en las variables clave (ITF, IPCF, etc.) se eliminan porque son esenciales para el análisis.\n",
        "Outliers: Los valores extremos de ingresos (ITF e IPCF) por encima del percentil 95 se eliminan para evitar sesgos.\n",
        "Variables categóricas: Las variables categóricas relevantes se convierten en numéricas usando pd.get_dummies para garantizar compatibilidad con modelos estadísticos.\n",
        "Duplicados: Se eliminan registros duplicados para mantener consistencia en los datos.\n",
        "División: Finalmente, las bases limpias se separan nuevamente en base_limpia_2004 y base_limpia_2024 para conservar la estructura de los datos originales."
      ],
      "metadata": {
        "id": "tOG-X8OG9uy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mostrar información inicial\n",
        "print(f\"Registros iniciales en base_2004: {base_2004_i.shape[0]}\")\n",
        "print(f\"Registros iniciales en base_2024: {base_2024_i.shape[0]}\")\n",
        "\n",
        "# Paso 1: Eliminar filas con valores faltantes en variables clave\n",
        "variables_clave = [\"REGION\", \"II7\", \"IV12_3\", \"IV6\", \"IV11\", \"II8\", \"ITF\", \"IPCF\",\"II1\",\"CH03\", \"CH12\", \"CH06\",\"CH04\",\"NIVEL_ED\",\"IX_TOT\",\"ESTADO\"]\n",
        "base_2004 = base_2004_i.dropna(subset=variables_clave)\n",
        "base_2024 = base_2024_i.dropna(subset=variables_clave)\n",
        "print(f\"Después de eliminar filas con valores faltantes:\")\n",
        "print(f\"- base_2004: {base_2004.shape[0]} registros\")\n",
        "print(f\"- base_2024: {base_2024.shape[0]} registros\")\n",
        "\n",
        "# Paso 2: Eliminar valores extremos en ITF e IPCF (por encima del percentil 95)\n",
        "for base, year in zip([base_2004, base_2024], [2004, 2024]):\n",
        "    itf_percentil_95 = base['ITF'].quantile(0.95)\n",
        "    ipcf_percentil_95 = base['IPCF'].quantile(0.95)\n",
        "    base = base[(base['ITF'] <= itf_percentil_95) & (base['IPCF'] <= ipcf_percentil_95)]\n",
        "    if year == 2004:\n",
        "        base_2004 = base\n",
        "    else:\n",
        "        base_2024 = base\n",
        "    print(f\"Después de eliminar valores extremos en ITF e IPCF (año {year}): {base.shape[0]} registros\")\n",
        "\n",
        "# Paso 3: Convertir variables categóricas relevantes a numéricas (encoding)\n",
        "variables_categoricas = ['CH04','CH03','' 'CH12', 'II7', 'IV12_3', 'II8', 'REGION','ESTADO']\n",
        "base_2004 = pd.get_dummies(base_2004, columns=variables_categoricas)\n",
        "base_2024 = pd.get_dummies(base_2024, columns=variables_categoricas)\n",
        "print(f\"Después de convertir variables categóricas a numéricas:\")\n",
        "print(f\"- base_2004: {base_2004.shape[0]} registros, {base_2004.shape[1]} columnas\")\n",
        "print(f\"- base_2024: {base_2024.shape[0]} registros, {base_2024.shape[1]} columnas\")\n",
        "\n",
        "# Paso 4: Eliminar duplicados\n",
        "base_2004 = base_2004.drop_duplicates()\n",
        "base_2024 = base_2024.drop_duplicates()\n",
        "print(f\"Después de eliminar duplicados:\")\n",
        "print(f\"- base_2004: {base_2004.shape[0]} registros\")\n",
        "print(f\"- base_2024: {base_2024.shape[0]} registros\")\n",
        "\n",
        "# Guardar las bases limpias\n",
        "base_2004.to_csv(\"base_2004_limpia.csv\", index=False)\n",
        "base_2024.to_csv(\"base_2024_limpia.csv\", index=False)\n",
        "print(\"Las bases limpias han sido guardadas como 'base_2004_limpia.csv' y 'base_2024_limpia.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGHoQgPd-yM4",
        "outputId": "2cd90f05-72f6-4e11-e02c-3a6382b4bfea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registros iniciales en base_2004: 45289\n",
            "Registros iniciales en base_2024: 46050\n",
            "Después de eliminar filas con valores faltantes:\n",
            "- base_2004: 45289 registros\n",
            "- base_2024: 46050 registros\n",
            "Después de eliminar valores extremos en ITF e IPCF (año 2004): 42080 registros\n",
            "Después de eliminar valores extremos en ITF e IPCF (año 2024): 42783 registros\n",
            "Después de convertir variables categóricas a numéricas:\n",
            "- base_2004: 42080 registros, 64 columnas\n",
            "- base_2024: 42783 registros, 62 columnas\n",
            "Después de eliminar duplicados:\n",
            "- base_2004: 41974 registros\n",
            "- base_2024: 42644 registros\n",
            "Las bases limpias han sido guardadas como 'base_2004_limpia.csv' y 'base_2024_limpia.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hogar_2004\",hogar_2004_filtered.shape)\n",
        "print(\"hogar_2024\",hogar_2024_filtered.shape)\n",
        "print(\"individual_2004\",individual_2004_filtered.shape)\n",
        "print(\"individual_2024\",individual_2024_filtered.shape)\n",
        "print(\"base_2004\",base_2004.shape)\n",
        "print(\"base_2024\",base_2024.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzwUCEMCisN",
        "outputId": "438cbf3c-88ad-43e5-e67a-b94968e0eea2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hogar_2004 (12816, 12)\n",
            "hogar_2024 (16104, 12)\n",
            "individual_2004 (45289, 8)\n",
            "individual_2024 (46050, 8)\n",
            "base_2004 (41974, 48)\n",
            "base_2024 (42644, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "filas_faltantes_2024 = base_2024_i[base_2024_i[variables_clave].isnull().any(axis=1)]\n",
        "\n"
      ],
      "metadata": {
        "id": "D0fNCtH-hlT_"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.\tConstruya variables (mínimo 3) que no estén en la base pero que sean relevantes para predecir individuos desocupados (por ejemplo, la proporción de personas que trabajan en el hogar)."
      ],
      "metadata": {
        "id": "h9-J1WrRBHm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre corto: PORC_DEP\n",
        "Descripción: Calcula el porcentaje de personas menores de 18 años o mayores de 65 años en relación con el total de integrantes del hogar.\n",
        "Requiere variable adicional: CH04 (edad del individuo) ya debería estar incluida en la base original."
      ],
      "metadata": {
        "id": "3m_zF3nKOJIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una copia auxiliar de las bases para trabajar\n",
        "base_2004_aux = base_2004.copy()\n",
        "base_2024_aux = base_2024.copy()\n",
        "\n",
        "# Calcular PORC_DEP: porcentaje de dependientes en el hogar usando CH06 (edad)\n",
        "# Dependientes: personas con edad < 18 o > 65 años\n",
        "base_2004_aux[\"PORC_DEP\"] = base_2004_aux.groupby(\"CODUSU\")[\"CH06\"].transform(\n",
        "    lambda x: ((x < 18) | (x > 65)).sum() / len(x) * 100\n",
        ")\n",
        "base_2024_aux[\"PORC_DEP\"] = base_2024_aux.groupby(\"CODUSU\")[\"CH06\"].transform(\n",
        "    lambda x: ((x < 18) | (x > 65)).sum() / len(x) * 100\n",
        ")\n",
        "\n",
        "# Guardar la variable en las bases originales\n",
        "base_2004[\"PORC_DEP\"] = base_2004_aux[\"PORC_DEP\"]\n",
        "base_2024[\"PORC_DEP\"] = base_2024_aux[\"PORC_DEP\"]\n",
        "\n",
        "# Verificar el resultado\n",
        "print(\"Base 2004 con PORC_DEP:\")\n",
        "print(base_2004[[\"CODUSU\", \"NRO_HOGAR\", \"CH06\", \"PORC_DEP\"]].head())\n",
        "\n",
        "print(\"\\nBase 2024 con PORC_DEP:\")\n",
        "print(base_2024[[\"CODUSU\", \"NRO_HOGAR\", \"CH06\", \"PORC_DEP\"]].head())\n",
        "\n",
        "# Si deseas guardar las bases actualizadas\n",
        "base_2004.to_csv(\"base_2004_con_porc_dep.csv\", index=False)\n",
        "base_2024.to_csv(\"base_2024_con_porc_dep.csv\", index=False)\n",
        "\n",
        "print(\"Bases actualizadas con PORC_DEP guardadas como 'base_2004_con_porc_dep.csv' y 'base_2024_con_porc_dep.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBrJUpBKOJzF",
        "outputId": "5d8372d7-7b62-419c-d994-8219b577ace1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base 2004 con PORC_DEP:\n",
            "   CODUSU NRO_HOGAR  CH06  PORC_DEP\n",
            "0  125098         1  79.0     100.0\n",
            "1  125397         1  67.0     100.0\n",
            "2  125515         1  74.0     100.0\n",
            "3  125558         1  54.0       0.0\n",
            "4  125558         1  51.0       0.0\n",
            "\n",
            "Base 2024 con PORC_DEP:\n",
            "                          CODUSU  NRO_HOGAR  CH06  PORC_DEP\n",
            "0  TQRMNOPUTHLMKQCDEGGFB00852588          1    44      40.0\n",
            "1  TQRMNOPUTHLMKQCDEGGFB00852588          1    22      40.0\n",
            "2  TQRMNOPUTHLMKQCDEGGFB00852588          1     3      40.0\n",
            "3  TQRMNOPPWHLLKRCDEGGFB00852574          1    54       0.0\n",
            "4  TQRMNOPPWHLLKRCDEGGFB00852574          1    53       0.0\n",
            "Bases actualizadas con PORC_DEP guardadas como 'base_2004_con_porc_dep.csv' y 'base_2024_con_porc_dep.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Educación promedio del hogar\n",
        "Nombre corto: EDU_PROM\n",
        "Descripción: Se asigna un puntaje a cada nivel educativo (CH12), y se calcula el promedio para cada hogar.\n",
        "Requiere variable adicional: CH12 ya debería estar incluida en la base original.\n",
        "Asignar puntajes a los niveles educativos:\n",
        "\n",
        "1 = Jardín/preescolar\n",
        "2 = Primario\n",
        "3 = EGB\n",
        "4 = Secundario\n",
        "5 = Polimodal\n",
        "6 = Terciario\n",
        "7 = Universitario\n",
        "8 = Posgrado universitario\n",
        "9 = Educación especial (0 puntos, ya que no aporta al promedio educativo)."
      ],
      "metadata": {
        "id": "q3RqWc0WJ6Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar puntajes a los niveles educativos en NIVEL_ED\n",
        "puntajes_educativos = {\n",
        "    1: 0,  # Primario incompleto\n",
        "    2: 1,  # Primario completo\n",
        "    3: 2,  # Secundario incompleto\n",
        "    4: 3,  # Secundario completo\n",
        "    5: 4,  # Superior universitario incompleto\n",
        "    6: 5,  # Superior universitario completo\n",
        "    7: 0,  # Sin instrucción\n",
        "    9: 0   # Ns/Nr\n",
        "}\n",
        "\n",
        "# Crear una copia auxiliar para trabajar\n",
        "base_2004_aux = base_2004.copy()\n",
        "base_2024_aux = base_2024.copy()\n",
        "\n",
        "# Mapear los puntajes educativos en NIVEL_ED\n",
        "base_2004_aux[\"NIVEL_ED_SCORE\"] = base_2004_aux[\"NIVEL_ED\"].map(puntajes_educativos)\n",
        "base_2024_aux[\"NIVEL_ED_SCORE\"] = base_2024_aux[\"NIVEL_ED\"].map(puntajes_educativos)\n",
        "\n",
        "# Calcular EDU_PROM (promedio educativo por hogar, agrupado por CODUSU)\n",
        "base_2004_aux[\"EDU_PROM\"] = base_2004_aux.groupby(\"CODUSU\")[\"NIVEL_ED_SCORE\"].transform(\"mean\")\n",
        "base_2024_aux[\"EDU_PROM\"] = base_2024_aux.groupby(\"CODUSU\")[\"NIVEL_ED_SCORE\"].transform(\"mean\")\n",
        "\n",
        "# Incorporar la variable EDU_PROM en las bases originales\n",
        "base_2004[\"EDU_PROM\"] = base_2004_aux[\"EDU_PROM\"]\n",
        "base_2024[\"EDU_PROM\"] = base_2024_aux[\"EDU_PROM\"]\n",
        "\n",
        "# Verificar el resultado\n",
        "print(\"Base 2004 con EDU_PROM:\")\n",
        "print(base_2004[[\"CODUSU\", \"NRO_HOGAR\", \"NIVEL_ED\", \"EDU_PROM\"]].head())\n",
        "\n",
        "print(\"\\nBase 2024 con EDU_PROM:\")\n",
        "print(base_2024[[\"CODUSU\", \"NRO_HOGAR\", \"NIVEL_ED\", \"EDU_PROM\"]].head())\n",
        "\n",
        "\n",
        "#Eliminar columnas String de Educación\n",
        "base_2004 = base_2004.drop(columns=[\"NIVEL_EDU\"], errors='ignore')\n",
        "base_2024 = base_2024.drop(columns=[\"NIVEL_EDU\"], errors='ignore')\n",
        "# Guardar las bases actualizadas\n",
        "base_2004.to_csv(\"base_2004_con_edu_prom.csv\", index=False)\n",
        "base_2024.to_csv(\"base_2024_con_edu_prom.csv\", index=False)\n",
        "\n",
        "print(\"Bases actualizadas con EDU_PROM guardadas como 'base_2004_con_edu_prom.csv' y 'base_2024_con_edu_prom.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCCoAF_2Tgci",
        "outputId": "7db015e5-df79-472c-d366-b5a3fa2a0aac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base 2004 con EDU_PROM:\n",
            "   CODUSU NRO_HOGAR NIVEL_ED  EDU_PROM\n",
            "0  125098         1        3       2.0\n",
            "1  125397         1        2       1.0\n",
            "2  125515         1        2       1.0\n",
            "3  125558         1        2       3.5\n",
            "4  125558         1        6       3.5\n",
            "\n",
            "Base 2024 con EDU_PROM:\n",
            "                          CODUSU  NRO_HOGAR  NIVEL_ED  EDU_PROM\n",
            "0  TQRMNOPUTHLMKQCDEGGFB00852588          1         3      2.40\n",
            "1  TQRMNOPUTHLMKQCDEGGFB00852588          1         5      2.40\n",
            "2  TQRMNOPUTHLMKQCDEGGFB00852588          1         7      2.40\n",
            "3  TQRMNOPPWHLLKRCDEGGFB00852574          1         4      3.75\n",
            "4  TQRMNOPPWHLLKRCDEGGFB00852574          1         4      3.75\n",
            "Bases actualizadas con EDU_PROM guardadas como 'base_2004_con_edu_prom.csv' y 'base_2024_con_edu_prom.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre corto: PERS_X_AMB\n",
        "Descripción:\n",
        "Esta variable mide el promedio de personas que habitan por cada ambiente o habitación disponible en el hogar. Se calcula dividiendo el número total de personas en el hogar (IX_TOT) entre el número de ambientes o habitaciones disponibles (II1). El valor resultante refleja la densidad de ocupación de los ambientes en cada hogar."
      ],
      "metadata": {
        "id": "k-Qy29bAURnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una copia auxiliar para trabajar\n",
        "base_2004_aux = base_2004.copy()\n",
        "base_2024_aux = base_2024.copy()\n",
        "\n",
        "# Calcular la variable PERS_X_AMB\n",
        "base_2004_aux[\"PERS_X_AMB\"] = base_2004_aux[\"IX_TOT\"] / base_2004_aux[\"II1\"]\n",
        "base_2024_aux[\"PERS_X_AMB\"] = base_2024_aux[\"IX_TOT\"] / base_2024_aux[\"II1\"]\n",
        "\n",
        "# Incorporar la variable PERS_X_AMB en las bases originales\n",
        "base_2004[\"PERS_X_AMB\"] = base_2004_aux[\"PERS_X_AMB\"]\n",
        "base_2024[\"PERS_X_AMB\"] = base_2024_aux[\"PERS_X_AMB\"]\n",
        "\n",
        "# Verificar el resultado\n",
        "print(\"Distribución de la variable PERS_X_AMB en base_2004:\")\n",
        "print(base_2004[\"PERS_X_AMB\"].describe())\n",
        "\n",
        "print(\"\\nDistribución de la variable PERS_X_AMB en base_2024:\")\n",
        "print(base_2024[\"PERS_X_AMB\"].describe())\n",
        "\n",
        "# Guardar las bases actualizadas\n",
        "base_2004.to_csv(\"base_2004_con_pers_x_amb.csv\", index=False)\n",
        "base_2024.to_csv(\"base_2024_con_pers_x_amb.csv\", index=False)\n",
        "\n",
        "print(\"Bases actualizadas con PERS_X_AMB guardadas como 'base_2004_con_pers_x_amb.csv' y 'base_2024_con_pers_x_amb.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9hBsBGHUWNF",
        "outputId": "5ca28429-1098-4ef3-84cc-2ffbe8741bfc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de la variable PERS_X_AMB en base_2004:\n",
            "count    4.197400e+04\n",
            "mean              inf\n",
            "std               NaN\n",
            "min      1.010101e-02\n",
            "25%      1.000000e+00\n",
            "50%      1.500000e+00\n",
            "75%      2.000000e+00\n",
            "max               inf\n",
            "Name: PERS_X_AMB, dtype: float64\n",
            "\n",
            "Distribución de la variable PERS_X_AMB en base_2024:\n",
            "count    4.264400e+04\n",
            "mean              inf\n",
            "std               NaN\n",
            "min      1.250000e-01\n",
            "25%      8.333333e-01\n",
            "50%      1.250000e+00\n",
            "75%      1.666667e+00\n",
            "max               inf\n",
            "Name: PERS_X_AMB, dtype: float64\n",
            "Bases actualizadas con PERS_X_AMB guardadas como 'base_2004_con_pers_x_amb.csv' y 'base_2024_con_pers_x_amb.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.\tPresenten estadísticas descriptivas de tres variables de la encuesta de hogar que ustedes creen que pueden ser relevantes para predecir la desocupación. Comenten las estadísticas obtenidas."
      ],
      "metadata": {
        "id": "TbE0y9O8Vu51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar las variables relevantes\n",
        "variables_hogar = [\"CH06\", \"PORC_DEP\", \"ITF\"]\n",
        "\n",
        "# Generar estadísticas descriptivas para cada variable\n",
        "def describir_variable(base, variable, nombre_variable):\n",
        "    print(f\"\\n--- Estadísticas descriptivas para {nombre_variable} ({variable}) ---\")\n",
        "    print(base[variable].describe(percentiles=[0.25, 0.5, 0.75]))\n",
        "    if base[variable].dtype == \"object\" or base[variable].nunique() <= 10:\n",
        "        print(\"\\nFrecuencias:\")\n",
        "        print(base[variable].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Estadísticas para base_2004\n",
        "print(\"=== Estadísticas descriptivas: Base 2004 ===\")\n",
        "for var in variables_hogar:\n",
        "    describir_variable(base_2004, var, var)\n",
        "\n",
        "# Estadísticas para base_2024\n",
        "print(\"\\n=== Estadísticas descriptivas: Base 2024 ===\")\n",
        "for var in variables_hogar:\n",
        "    describir_variable(base_2024, var, var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiGy9xErVx3t",
        "outputId": "43b2651c-30b2-461c-e5f7-f2fa649d49d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Estadísticas descriptivas: Base 2004 ===\n",
            "\n",
            "--- Estadísticas descriptivas para CH06 (CH06) ---\n",
            "count     41974.0\n",
            "unique       99.0\n",
            "top          12.0\n",
            "freq        892.0\n",
            "Name: CH06, dtype: float64\n",
            "\n",
            "--- Estadísticas descriptivas para PORC_DEP (PORC_DEP) ---\n",
            "count    41974.000000\n",
            "mean        42.173727\n",
            "std         25.908456\n",
            "min          0.000000\n",
            "25%         25.000000\n",
            "50%         50.000000\n",
            "75%         60.000000\n",
            "max        100.000000\n",
            "Name: PORC_DEP, dtype: float64\n",
            "\n",
            "--- Estadísticas descriptivas para ITF (ITF) ---\n",
            "count    41974.000000\n",
            "mean       871.400534\n",
            "std        614.842043\n",
            "min          0.000000\n",
            "25%        400.000000\n",
            "50%        700.000000\n",
            "75%       1200.000000\n",
            "max       3000.000000\n",
            "Name: ITF, dtype: float64\n",
            "\n",
            "=== Estadísticas descriptivas: Base 2024 ===\n",
            "\n",
            "--- Estadísticas descriptivas para CH06 (CH06) ---\n",
            "count    42644.000000\n",
            "mean        36.080855\n",
            "std         22.306795\n",
            "min         -1.000000\n",
            "25%         17.000000\n",
            "50%         34.000000\n",
            "75%         53.000000\n",
            "max        101.000000\n",
            "Name: CH06, dtype: float64\n",
            "\n",
            "--- Estadísticas descriptivas para PORC_DEP (PORC_DEP) ---\n",
            "count    42644.000000\n",
            "mean        37.709877\n",
            "std         28.154580\n",
            "min          0.000000\n",
            "25%         16.666667\n",
            "50%         37.500000\n",
            "75%         50.000000\n",
            "max        100.000000\n",
            "Name: PORC_DEP, dtype: float64\n",
            "\n",
            "--- Estadísticas descriptivas para ITF (ITF) ---\n",
            "count    4.264400e+04\n",
            "mean     3.911234e+05\n",
            "std      3.444188e+05\n",
            "min      0.000000e+00\n",
            "25%      0.000000e+00\n",
            "50%      3.500000e+05\n",
            "75%      6.010000e+05\n",
            "max      1.400000e+06\n",
            "Name: ITF, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Crear una copia de las bases originales\n",
        "base_2004_aux = base_2004.copy()\n",
        "base_2024_aux = base_2024.copy()\n",
        "\n",
        "\n",
        "# Paso 2: Separar en variables dependientes (y) e independientes (X)\n",
        "# Eliminar 'DESOCUPADO' y 'YEAR' de las variables independientes\n",
        "y_2004 = base_2004_aux['ESTADO_Desocupado']\n",
        "X_2004 = base_2004_aux.drop(columns=['ESTADO_Desocupado', 'YEAR'])\n",
        "\n",
        "y_2024 = base_2024_aux['ESTADO_Desocupado']\n",
        "X_2024 = base_2024_aux.drop(columns=['ESTADO_Desocupado', 'YEAR'])\n",
        "\n",
        "# Agregar columna de unos para el término constante (intercepto)\n",
        "X_2004['INTERCEPT'] = 1\n",
        "X_2024['INTERCEPT'] = 1\n",
        "\n",
        "# Paso 3: Dividir en entrenamiento (70%) y prueba (30%) con semilla 101\n",
        "X_train_2004, X_test_2004, y_train_2004, y_test_2004 = train_test_split(\n",
        "    X_2004, y_2004, test_size=0.3, random_state=101\n",
        ")\n",
        "\n",
        "X_train_2024, X_test_2024, y_train_2024, y_test_2024 = train_test_split(\n",
        "    X_2024, y_2024, test_size=0.3, random_state=101\n",
        ")\n",
        "\n",
        "# Paso 4: Verificar resultados\n",
        "print(\"=== Año 2004 ===\")\n",
        "print(\"Conjunto de entrenamiento (X_train):\", X_train_2004.shape)\n",
        "print(\"Conjunto de prueba (X_test):\", X_test_2004.shape)\n",
        "print(\"Variable dependiente entrenamiento (y_train):\", y_train_2004.shape)\n",
        "print(\"Variable dependiente prueba (y_test):\", y_test_2004.shape)\n",
        "\n",
        "print(\"\\n=== Año 2024 ===\")\n",
        "print(\"Conjunto de entrenamiento (X_train):\", X_train_2024.shape)\n",
        "print(\"Conjunto de prueba (X_test):\", X_test_2024.shape)\n",
        "print(\"Variable dependiente entrenamiento (y_train):\", y_train_2024.shape)\n",
        "print(\"Variable dependiente prueba (y_test):\", y_test_2024.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP4egtF-JqpX",
        "outputId": "0502fe8e-fa3d-4126-b049-14f4c48fa51f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Año 2004 ===\n",
            "Conjunto de entrenamiento (X_train): (29381, 66)\n",
            "Conjunto de prueba (X_test): (12593, 66)\n",
            "Variable dependiente entrenamiento (y_train): (29381,)\n",
            "Variable dependiente prueba (y_test): (12593,)\n",
            "\n",
            "=== Año 2024 ===\n",
            "Conjunto de entrenamiento (X_train): (29850, 64)\n",
            "Conjunto de prueba (X_test): (12794, 64)\n",
            "Variable dependiente entrenamiento (y_train): (29850,)\n",
            "Variable dependiente prueba (y_test): (12794,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Función para realizar validación cruzada y evaluación\n",
        "def validar_lambda(X_train, y_train, X_test, y_test, alphas, year):\n",
        "    print(f\"\\n=== Año {year}: Selección de alpha mediante Validación Cruzada ===\")\n",
        "\n",
        "    # Paso 1: Entrenar Lasso con validación cruzada para seleccionar alpha\n",
        "    modelo_lasso = LassoCV(alphas=alphas, cv=5, random_state=101)\n",
        "    modelo_lasso.fit(X_train, y_train)\n",
        "\n",
        "    # Obtener el mejor alpha\n",
        "    mejor_alpha = modelo_lasso.alpha_\n",
        "    print(f\"Mejor valor de alpha (λ) para {year}: {mejor_alpha}\")\n",
        "\n",
        "    # Paso 2: Evaluar el modelo en el conjunto de prueba\n",
        "    y_pred_test = modelo_lasso.predict(X_test)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    print(f\"Error cuadrático medio en el conjunto de prueba ({year}): {mse_test:.4f}\")\n",
        "\n",
        "# Valores de alpha a evaluar\n",
        "valores_alpha = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "#X_train_2004\n",
        "# Año 2004\n",
        "\n",
        "validar_lambda(X_train_2004, y_train_2004, X_test_2004, y_test_2004, valores_alpha, 2004)\n",
        "\n",
        "# Año 2024\n",
        "validar_lambda(X_train_2024, y_train_2024, X_test_2024, y_test_2024, valores_alpha, 2024)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLiVhmRC-s7V",
        "outputId": "818b2878-0852-457b-c657-532de1567ee1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Año 2004: Selección de alpha mediante Validación Cruzada ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains infinity or a value too large for dtype('float64').",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c5cf9a608da1>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Año 2004\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mvalidar_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_2004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_2004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_2004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_2004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalores_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2004\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Año 2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-c5cf9a608da1>\u001b[0m in \u001b[0;36mvalidar_lambda\u001b[0;34m(X_train, y_train, X_test, y_test, alphas, year)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Paso 1: Entrenar Lasso con validación cruzada para seleccionar alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodelo_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodelo_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Obtener el mejor alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   2126\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m         \"\"\"\n\u001b[0;32m-> 2128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1642\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             )\n\u001b[0;32m-> 1644\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1645\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1065\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    }
  ]
}