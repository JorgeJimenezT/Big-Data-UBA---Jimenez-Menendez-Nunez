{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Dh8MkXaG-c9Y",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "# Big Data (UBA) -  2024\n",
        "\n",
        "## Trabajo Práctico 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhBlm6mZ-c9e"
      },
      "source": [
        "### Reglas de formato y presentación\n",
        "- El trabajo debe estar debidamente documentado comentado (utilizando #) para que tanto los docentes como sus compañeros puedan comprender el código fácilmente.\n",
        "\n",
        "- El mismo debe ser completado en este Jupyter Notebook y entregado como tal, es decir en un archivo .ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEjGaa4U-c9g"
      },
      "source": [
        "### Fecha de entrega:\n",
        "Viernes 25 de octubre a las 13:00 hs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9TU2y7E-c9h"
      },
      "source": [
        "### Modalidad de entrega\n",
        "- Al finalizar el trabajo práctico deben hacer un último <i>commit</i> en su repositorio de GitHub llamado “Entrega final del tp”.\n",
        "- Asegurense de haber creado una carpeta llamada TP1. Este Jupyter Notebook y el correspondiente al TP1 deben estar dentro de esa carpeta.\n",
        "- También deben enviar el link de su repositorio -para que pueda ser clonado y corregido- a mi correo m.n.romero91@gmail.com\n",
        "- La última versión en el repositorio es la que será evaluada. Por lo que es importante que:\n",
        "    - No envien el correo hasta no haber terminado y estar seguros de que han hecho el <i>commit y push</i> a la versión final que quieren entregar. Debido a que se pueden tomar hasta 3 días de extensión a lo largo del curso, no se corregirán sus tareas hasta no recibir el correo.\n",
        "    - No hagan nuevos <i>push</i> despues de haber entregado su versión final. Esto generaría confusión acerca de que versión es la que quieren que se les corrija."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM0Uz8Eg6TgX"
      },
      "source": [
        "### Parte A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXbrPraa-c9i"
      },
      "source": [
        "#### Ejercicio 1\n",
        "Usando la API de Mercado Libre, obtener los ítems de una consulta de búsqueda. Pueden buscar cualquier producto de su interés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxBCIOC46TgX",
        "outputId": "26eea572-ed06-40b1-d800-95cdc008cb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primer resultado encontrado para 'aire acondicionado':\n",
            "Nombre: Aire Acondicionado Split Frio Calor Philco Phs32ha4cn Color Blanco\n",
            "Precio: 767999 ARS\n",
            "Link: https://www.mercadolibre.com.ar/aire-acondicionado-split-frio-calor-philco-phs32ha4cn-color-blanco/p/MLA19695532#wid=MLA1449190787&sid=unknown\n",
            "Descripción del artículo: Con más de 100 años de trayectoria y gran presencia a nivel mundial, Philco es considerada una de las marcas pioneras en la industria de tecnología y electrodomésticos. Su amplia gama de productos de refrigeración se caracteriza por la calidad y la innovación constante.Climatizar tus espacios a lo largo del año es algo importante para tu comodidad. Un aire acondicionado frío/calor Philco Split es la mejor decisión, ya que conseguís una mejor relación costo-beneficio.\n",
            "\n",
            "Diseño adecuado a tus espacios\n",
            "El tipo de aire split es de bajo consumo energético, de fácil mantenimiento y sumamente silencioso ya que cuenta con una unidad exterior.\n",
            "\n",
            "Reducción de humedad\n",
            "El deshumidificador absorbe el agua del aire y disminuye la molesta humedad, creando un ambiente confortable y de calidad.\n",
            "\n",
            "Programá de acuerdo a tus necesidades\n",
            "Cuando las personas descansan su temperatura corporal baja gradualmente. Por eso, este aire cuenta con la función sleep, que hace que la temperatura del ambiente aumente a medida que pasa el tiempo. No tendrás que levantarte a apagarlo y podrás disfrutar de un sueño placentero.   \n",
            " Información técnica: Refrigerante: R410A Capacidad frío: 3400 W Consumo eléctrico frío: 1040 W Capacidad calor: 3100 W Consumo eléctrico calor: 910 W Ef. Energética (Frío) - E.E.R.: 3.27 -Clase A Ef. Energética (Calor) - C.O.P.: 341 -Clase B Nivel de ruido máximo (int): 39 dB Cañeria de intercon. (Liq./Gas) 1/4\" 1/2\"\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Parámetros de búsqueda\n",
        "buscar = \"aire acondicionado\"\n",
        "url = \"https://api.mercadolibre.com/sites/{}/search?q={}\".format(\"MLA\", buscar.replace(\" \", \"%20\"))\n",
        "\n",
        "# Hacemos el pedido o request y obtenemos la respuesta\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificamos si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Guardamos el resultado en un diccionario (json)\n",
        "    data = response.json()\n",
        "\n",
        "    # Verificamos si hay resultados en la búsqueda\n",
        "    if len(data['results']) > 0:\n",
        "        # Mostramos el precio y el enlace del primer resultado\n",
        "        primer_resultado = data['results'][0]\n",
        "        print(f\"Primer resultado encontrado para '{buscar}':\")\n",
        "        print(f\"Nombre: {primer_resultado['title']}\")\n",
        "        print(f\"Precio: {primer_resultado['price']} ARS\")\n",
        "        print(f\"Link: {primer_resultado['permalink']}\")\n",
        "\n",
        "        # Obtenemos la descripción detallada del primer ítem\n",
        "        item_id = primer_resultado['id']\n",
        "        url_descripcion = f\"https://api.mercadolibre.com/items/{item_id}/description\"\n",
        "        response2 = requests.get(url_descripcion)\n",
        "\n",
        "        # Si se obtiene la descripción, la mostramos\n",
        "        if response2.status_code == 200:\n",
        "            descripcion = response2.json().get('plain_text', 'No hay descripción disponible.')\n",
        "            print(f\"Descripción del artículo: {descripcion}\")\n",
        "        else:\n",
        "            print(\"No se pudo obtener la descripción del artículo.\")\n",
        "    else:\n",
        "        print(\"No se encontraron resultados.\")\n",
        "else:\n",
        "    print(f\"Error al hacer la solicitud: {response.status_code}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RJY_6ww6TgY"
      },
      "source": [
        "#### Ejercicio 2\n",
        "Guarden los precios de los ítems obtenidos en un dataframe y calculen el precio promedio, el mínimo y el máximo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4yaxgIg6TgY"
      },
      "outputs": [],
      "source": [
        "# Resolver acá\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ1QBdse6TgY"
      },
      "source": [
        "#### Ejercicio 3\n",
        "Armen un histograma de los precios. ¿Ven algún <i>outlier<i>?\n",
        "Nota: pueden usar la librería de Matplotlib o la de Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOc9UuXb6TgY"
      },
      "outputs": [],
      "source": [
        "# Resolver acá\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQg9Pj0g6TgY"
      },
      "source": [
        "#### Ejercicio 4\n",
        "Realicen alguna consulta adicional utilizando la API de Mercado Libre (debe ser alguna consulta que no se haya visto en clase. Por ejemplo, obtener los ítems de un vendedor en particular, obtener los productos de una categoría u otros). Analicen los resultados y comenten uno o dos que les parezcan interesantes (por ejemplo, precios promedio de los productos de un vendedor, diferencia entre el precio original y actual, si acepta mercado pago para la compra de productos, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyTK1Ctl6TgY"
      },
      "outputs": [],
      "source": [
        "# Resolver acá\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np7yvLOQ6TgY"
      },
      "source": [
        "### Parte B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQOhBwQo6TgZ"
      },
      "source": [
        "#### Ejercicio 5\n",
        "De la página de noticias del [diario La Nación](https://www.lanacion.com.ar/), utilicen herramientas de web scraping para obtener los links de las noticias de la portada. Guarden los links obtenidos en un dataframe y expórtenlo a un archivo de excel.\n",
        "\n",
        "Nota 1: es posible que logren obtener los links a las noticias sin el dominio: \"https://www.lanacion.com.ar/\". De ser así, concatenen el dominio a la ruta del link obtenido, tal que se obtenga un link al que se pueda acceder. Es decir, que las cadenas de caracteres finales tendrán la forma: https://www.lanacion.com.ar/*texto_obtenido*)\n",
        "\n",
        "Nota 2: junto con su entrega, adjunten una captura de la página de noticias al momento de correr su código. Eso servirá al momento de la corrección para verificar que los links obtenidos hacen referencia a las noticias de ese día y hora."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKqQOhSI8zgm",
        "outputId": "b0a74450-3dae-4632-af8b-3974bde820dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YPTTNuZ36TgZ",
        "outputId": "e3742cda-aa49-4763-bfe0-0f7c2c58f453"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c284789f-890c-4949-bd7e-3050b2e140ec\", \"lanacion_news_links_2024-10-24_00-58-27.xlsx\", 12644)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Links de noticias extraídos y guardados en lanacion_news_links_2024-10-24_00-58-27.xlsx\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# URL de la página principal de La Nación\n",
        "url = \"https://www.lanacion.com.ar/\"\n",
        "\n",
        "# Realizar la solicitud GET\n",
        "response = requests.get(url)\n",
        "\n",
        "# Comprobar que la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Encontrar todos los elementos 'a' que contengan los enlaces con 'nid'\n",
        "    links = []\n",
        "    categories = []\n",
        "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link['href']\n",
        "        # Filtrar solo los enlaces que contienen 'nid'\n",
        "        if 'nid' in href:\n",
        "            if href.startswith('/'):\n",
        "                full_link = f\"https://www.lanacion.com.ar{href}\"\n",
        "            elif href.startswith(\"https://www.lanacion.com.ar\"):\n",
        "                full_link = href\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            # Identificar la categoría a partir de la URL\n",
        "            if '/politica' in href:\n",
        "                category = 'Política'\n",
        "            elif '/economia' in href:\n",
        "                category = 'Economía'\n",
        "            elif '/deportes' in href:\n",
        "                category = 'Deportes'\n",
        "            elif '/espectaculos' in href:\n",
        "                category = 'Espectáculos'\n",
        "            elif '/sociedad' in href:\n",
        "                category = 'Sociedad'\n",
        "            elif '/internacional' in href:\n",
        "                category = 'Internacional'\n",
        "            else:\n",
        "                category = 'Otros'\n",
        "\n",
        "            # Agregar los enlaces y categorías a las listas\n",
        "            links.append((full_link, category, current_datetime))\n",
        "\n",
        "    # Crear un DataFrame con los links y las categorías\n",
        "    df = pd.DataFrame(links, columns=[\"Link\", \"Categoría\", \"Fecha y Hora de Obtención\"])\n",
        "\n",
        "    # Exportar a Excel\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    output_filename = f\"lanacion_news_links_{timestamp}.xlsx\"\n",
        "    df.to_excel(output_filename, index=False)\n",
        "\n",
        "    # Descargar el archivo en Colab\n",
        "    files.download(output_filename)\n",
        "\n",
        "    print(f\"Links de noticias extraídos y guardados en {output_filename}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "TP1 - Parte 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}